{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
    "choosen_embeddings = HuggingFaceInstructEmbeddings(model_name = 'hkunlp/instructor-xl',  \n",
    "                                        model_kwargs={\"device\":\"cuda:0\"},\n",
    "                                        encode_kwargs ={'normalize_embeddings': True} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "choosen_embeddings = OllamaEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from src.constants import *\n",
    "from src.utils import read_yaml, extract_links, write_list_as_txt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(CUSTOM_ENV_NAME)\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_CSE_ID\"] = os.getenv(\"GOOGLE_CSE_ID\")\n",
    "\n",
    "from langchain_community.utilities import GoogleSearchAPIWrapper\n",
    "\n",
    "\n",
    "def extract_related_links ():\n",
    "    \"\"\"\n",
    "    read context and number of results from params.yaml\n",
    "    returns a text file with saved list of web pages to be vectorized\n",
    "    \"\"\"\n",
    "    # extract the context and length of search for websites\n",
    "    params = read_yaml(1, PARAMS_FILE_PATH)\n",
    "    search_context = params['Web_page_search_context']\n",
    "    search_num = params['number_of_pages']\n",
    "    print (search_context, \"for \", search_num, \" pages\")\n",
    "\n",
    "    # use the context and length to do a google search using an api wrapper\n",
    "    api_wrapper = GoogleSearchAPIWrapper( siterestrict = False )\n",
    "    link_in_dict = api_wrapper.results (search_context  , search_num )\n",
    "    print ( \"Activity  2 : Done: getting webpages from Google wrapper\")\n",
    "\n",
    "    # Extract the links from the above dictionary to a list so as to be used for webbasedloader\n",
    "    link_in_list =  extract_links( 3,  link_in_dict , 'link')\n",
    "\n",
    "    # write the list in a txt file (always overwrites)\n",
    "    write_list_as_txt ( 4, link_in_list )\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity  1 : Done: reading yaml file\n",
      "novartis Iptacopan pnh competitors for  2  pages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study2\\git\\Environments\\novas\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `GoogleSearchAPIWrapper` was deprecated in LangChain 0.0.33 and will be removed in 0.3.0. An updated version of the class exists in the langchain-google-community package and should be used instead. To use it run `pip install -U langchain-google-community` and import as `from langchain_google_community import GoogleSearchAPIWrapper`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity  2 : Done: getting webpages from Google wrapper\n",
      "Activity  3 : Done: extracting webpage from dict\n",
      "              txt status: file already exists, overwriting it \n",
      "Activity  4 : Done: writing webpage links to txt\n"
     ]
    }
   ],
   "source": [
    "extract_related_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1722655218.63517 1722655218.636168 0.0009980201721191406\n",
      "0:00:00.007979\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import timedelta\n",
    "start = time.time()\n",
    "for a in range (10000):\n",
    "    pass\n",
    "end = time.time()\n",
    "print ( start, end , end - start  )\n",
    "for a in range (100000):\n",
    "    pass\n",
    "end = time.time()\n",
    "print(timedelta(seconds=time.time()-start) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "novas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
