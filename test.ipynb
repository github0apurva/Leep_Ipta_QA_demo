{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Web_page_search_context = \"novartis Iptacopan competitors\"\n",
    "number_of_pages = 2\n",
    "chunk_size = 1000\n",
    "chunk_overlap =20\n",
    "docs_to_vectorize = 1000\n",
    "embeddings_to_use ='Ollama'\n",
    "model_to_use = 'Ollama'\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import yaml\n",
    "from pathlib import Path \n",
    "from box.exceptions import BoxValueError\n",
    "\n",
    "\n",
    "CUSTOM_ENV_PATH = lambda a : '/'.join(os.get_exec_path()[0].split('\\\\')[:-2])+'/'+a\n",
    "CUSTOM_ENV_NAME = CUSTOM_ENV_PATH('chatter.env')\n",
    "\n",
    "def extract_links ( ac, link_in_dict, dict_key ='link' ):\n",
    "    \"\"\"\n",
    "    reads a list of dictionaries and returns specific value for a key \n",
    "    \"\"\"\n",
    "    link_in_list = [ link_in_dict[i][dict_key] for i in range(len(link_in_dict)) ]\n",
    "    print ( \"Activity \", ac, \": Done: extracting webpage from dict\")\n",
    "    return link_in_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min (docs_to_vectorize, len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "novartis Iptacopan competitors for  2  pages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study2\\git\\Environments\\novas\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `GoogleSearchAPIWrapper` was deprecated in LangChain 0.0.33 and will be removed in 0.3.0. An updated version of the class exists in the langchain-google-community package and should be used instead. To use it run `pip install -U langchain-google-community` and import as `from langchain_google_community import GoogleSearchAPIWrapper`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity 2: Done: getting webpages from Google wrapper\n",
      "Activity  3 : Done: extracting webpage from dict\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(CUSTOM_ENV_NAME)\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_CSE_ID\"] = os.getenv(\"GOOGLE_CSE_ID\")\n",
    "\n",
    "from langchain_community.utilities import GoogleSearchAPIWrapper\n",
    "\n",
    "\n",
    "def extract_related_links ():\n",
    "    \"\"\"\n",
    "    read context and number of results from params.yaml\n",
    "    returns a text file with saved list of web pages to be vectorized\n",
    "    \"\"\"\n",
    "    # extract the context and length of search for websites\n",
    "    search_context =Web_page_search_context\n",
    "    search_num = number_of_pages\n",
    "    print (search_context, \"for \", search_num, \" pages\")\n",
    "\n",
    "    # use the context and length to do a google search using an api wrapper\n",
    "    api_wrapper = GoogleSearchAPIWrapper( siterestrict = False )\n",
    "    link_in_dict = api_wrapper.results (search_context  , search_num )\n",
    "    print ( \"Activity 2: Done: getting webpages from Google wrapper\")\n",
    "    # Extract the links from the above dictionary to a list so as to be used for webbasedloader\n",
    "    link_in_list =  extract_links( 3,  link_in_dict , 'link')\n",
    "\n",
    "    return link_in_list\n",
    "\n",
    "list_link = extract_related_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.novartis.com/news/media-releases/novartis-investigational-iptacopan-phase-iii-study-demonstrates-clinically-meaningful-and-highly-statistically-significant-proteinuria-reduction-patients-iga-nephropathy-igan',\n",
       " 'https://www.biospace.com/article/novartis-pnh-trial-results-put-pressure-on-astrazeneca-s-ultomiris-and-soliris/']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders import WebBaseLoader\n",
    "# import bs4\n",
    "# list_link = [\"https://www.novartis.com/news/media-releases/novartis-investigational-iptacopan-phase-iii-study-demonstrates-clinically-meaningful-and-highly-statistically-significant-proteinuria-reduction-patients-iga-nephropathy-igan\" , \"https://www.biospace.com/article/novartis-pnh-trial-results-put-pressure-on-astrazeneca-s-ultomiris-and-soliris/\"]\n",
    "# loader = WebBaseLoader(web_path = list_link,)\n",
    "#                         # bs_kwargs= dict( parse_only = bs4.SoupStrainer\n",
    "#                         #                 (class_ = (\"post-content\",\"post-title\",\"post-header\") )), )\n",
    " \n",
    "# web_docs = loader.load()\n",
    "# web_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path \n",
    "import os\n",
    "\n",
    "from src.constants import *\n",
    "from src.utils import read_yaml, read_from_text\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(CUSTOM_ENV_NAME)\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import FewShotChatMessagePromptTemplate\n",
    "from langchain import hub\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "import streamlit as st\n",
    "import time\n",
    "\n",
    "def create_retreiver (links_to_load):\n",
    "    \"\"\"\n",
    "    read chunk size and overlap from params.yaml\n",
    "    \"\"\"\n",
    "    # # read the list of webpage to be taken\n",
    "    # links_to_load = read_from_text ( 5, WEB_PAGE_TXT )\n",
    "\n",
    "    # use a loader to get all content\n",
    "    loader = WebBaseLoader(web_paths = links_to_load,)\n",
    "                    #        bs_kwargs= dict(parse_only = bs4.SoupStrainer(\n",
    "                    #        class_ = (\"post-title\",\"post-content\",\"post-header\")\n",
    "                    #    )),)    \n",
    "    web_docs = loader.load()\n",
    "    print (\"size of the web docs : \",len(web_docs))\n",
    "    print (\"Activity \", 6, \": Done: webpage content from links\")\n",
    "    \n",
    "    # extract the size and overlap chars from param file\n",
    "    print (chunk_size, \"is the chunk size choosen with \", chunk_overlap, \" chars overlaps \")\n",
    "\n",
    "    # splitting the docs based on above size etc\n",
    "    documents = RecursiveCharacterTextSplitter(chunk_size = chunk_size, chunk_overlap = chunk_overlap).split_documents(web_docs)\n",
    "    # taking only top n docs\n",
    "    docs_to_vectorize_take = min ( docs_to_vectorize, len(web_docs))\n",
    "    documents_filtered = documents[:docs_to_vectorize_take]\n",
    "    # choosing the embeddings to use\n",
    "    if embeddings_to_use == \"Instruct\":\n",
    "        print ( \"Instruct Embeddings\" )\n",
    "        choosen_embeddings = HuggingFaceInstructEmbeddings(model_name = 'hkunlp/instructor-xl',  \n",
    "                                                   model_kwargs={\"device\":\"cpu\"},\n",
    "                                                   encode_kwargs ={'normalize_embeddings': True} )\n",
    "    else :\n",
    "        choosen_embeddings = OllamaEmbeddings()\n",
    "        print ( \"Ollama Embeddings\" )\n",
    "    # creatign vector store and eventually retreiver\n",
    "    verctordb = FAISS.from_documents(documents_filtered, choosen_embeddings )\n",
    "    #retriever = verctordb.as_retriever()\n",
    "    return verctordb\n",
    "\n",
    "\n",
    "\n",
    "def get_retrieval_chain (retriever):\n",
    "    # get prompt\n",
    "    # prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "    # print( prompt.messages )\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an assistant for question-answering tasks. Use the provided context only to answer the question. \n",
    "    {prompt_examples}\n",
    "    If you don't know the answer, just say that you don't know. {prompt_text}\n",
    "    Please provide the most accurate response based on the question.\n",
    "    <context>\n",
    "    {context}\n",
    "    <context>\n",
    "    Questions: {input}\n",
    "    \"\"\")\n",
    "\n",
    "    #llm = Ollama(model = \"llama2\")\n",
    "    llm= ChatOllama(model=\"llama2\")\n",
    "\n",
    "    # creating document chain\n",
    "    document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "    retrieval_chain = create_retrieval_chain (retriever, document_chain)\n",
    "    return retrieval_chain\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def talk_to_stream (retrieval_chain):\n",
    "    st.title(\"Demo with LLAMA2\")\n",
    "\n",
    "    input_text = st.text_input (\"Input the question you have about Iptacopan \")\n",
    "    prompt_text = \" Use three sentences maximum and keep the answer concise. \"\n",
    "    prompt_few_text = \"\"\" \"Input\":\"where was Iptacopan discovered?\", \"Output\": \"iscovered at the Novartis Biomedical Research, iptacopan is currently in development for a range of complement-mediated diseases including paroxysmal nocturnal hemoglobinuria (PNH), immunoglobulin A nephropathy (IgAN), C3 glomerulopathy (C3G), immune complex membranoproliferative glomerulonephritis (IC-MPGN) and atypical hemolytic uremic syndrome (aHUS)\", \n",
    "    \"Input\":\"How does Iptacopan compares with Soliris\", \"Output\": \"Iptacopan was compared to AstraZeneca/Alexion’s Soliris (eculizumab) and Ultomiris (ravulizumab). Both drugs are anti-complement component 5 (C5) monoclonal antibodies, approved for PNH and atypical hemolytic uremic syndrome, generalized myasthenia gravis and neuromyelitis optica spectrum disorder\".\"\"\"\n",
    "    prompt_examples = \"Few sample questions and answers are \" + prompt_few_text\n",
    "\n",
    "    #input_text = \"what is Iptacopan\"\n",
    "    if input_text:\n",
    "        start_time = time.process_time()\n",
    "        response = retrieval_chain.invoke ({\"input\":input_text, \"prompt_text\":prompt_text, \"prompt_examples\": prompt_examples })\n",
    "        print (\"response time: \",time.process_time()-start_time)\n",
    "        print ( response['answer'] )\n",
    "        st.write(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = \" Use three sentences maximum and keep the answer concise. \"\n",
    "prompt_examples = \"\"\"Few sample questions and answers are \n",
    "\"Input\":\"where was Iptacopan discovered?\", \"Output\": \"iscovered at the Novartis Biomedical Research, iptacopan is currently in development for a range of complement-mediated diseases including paroxysmal nocturnal hemoglobinuria (PNH), immunoglobulin A nephropathy (IgAN), C3 glomerulopathy (C3G), immune complex membranoproliferative glomerulonephritis (IC-MPGN) and atypical hemolytic uremic syndrome (aHUS)\", \n",
    "\"Input\":\"How does Iptacopan compares with Soliris\", \"Output\": \"Iptacopan was compared to AstraZeneca/Alexion’s Soliris (eculizumab) and Ultomiris (ravulizumab). Both drugs are anti-complement component 5 (C5) monoclonal antibodies, approved for PNH and atypical hemolytic uremic syndrome, generalized myasthenia gravis and neuromyelitis optica spectrum disorder\".\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"\n",
    "You are an assistant for question-answering tasks. Use the provided context only to answer the question. \n",
    "{prompt_examples}\n",
    "If you don't know the answer, just say that you don't know. {prompt_text}\n",
    "Please provide the most accurate response based on the question.\n",
    "<context>\n",
    "{context}\n",
    "<context>\n",
    "Questions: {input}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the web docs :  10\n",
      "Activity  6 : Done: webpage content from links\n",
      "1000 is the chunk size choosen with  20  chars overlaps \n",
      "Ollama Embeddings\n"
     ]
    }
   ],
   "source": [
    "# retr = create_retreiver (list_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the web docs :  2\n",
      "Activity  6 : Done: webpage content from links\n",
      "1000 is the chunk size choosen with  20  chars overlaps \n",
      "Ollama Embeddings\n"
     ]
    }
   ],
   "source": [
    "vcdb = create_retreiver (list_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vcdb.save_local ( os.getcwd() , 'nova_vector_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Study2\\\\git\\\\Leep_Ipta_QA_demo'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vcdb_load = FAISS.load_local ( 'd:/Study2/git/Leep_Ipta_QA_demo',index_name  = 'nova_vector_db',\n",
    "#                                embeddings = OllamaEmbeddings() ,allow_dangerous_deserialization = True   ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc  = get_retrieval_chain (vcdb.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the competitors of Iptacopan are:\n",
      "\n",
      "1. AstraZeneca/Alexion's Soliris (eculizumab) and Ultomiris (ravulizumab). These drugs are also anti-complement component 5 (C5) monoclonal antibodies, approved for PNH and atypical hemolytic uremic syndrome, generalized myasthenia gravis, and neuromyelitis optica spectrum disorder.\n",
      "\n",
      "Please note that this information is based on the provided context and may not be up-to-date or comprehensive.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"what are the competitors of Iptacopan\"\n",
    "prompt_text = \" Use three sentences maximum and keep the answer concise. \"\n",
    "prompt_few_text = \"\"\" \"Input\":\"where was Iptacopan discovered?\", \"Output\": \"iscovered at the Novartis Biomedical Research, iptacopan is currently in development for a range of complement-mediated diseases including paroxysmal nocturnal hemoglobinuria (PNH), immunoglobulin A nephropathy (IgAN), C3 glomerulopathy (C3G), immune complex membranoproliferative glomerulonephritis (IC-MPGN) and atypical hemolytic uremic syndrome (aHUS)\", \n",
    "\"Input\":\"How does Iptacopan compares with Soliris\", \"Output\": \"Iptacopan was compared to AstraZeneca/Alexion’s Soliris (eculizumab) and Ultomiris (ravulizumab). Both drugs are anti-complement component 5 (C5) monoclonal antibodies, approved for PNH and atypical hemolytic uremic syndrome, generalized myasthenia gravis and neuromyelitis optica spectrum disorder\".\"\"\"\n",
    "\n",
    "prompt_examples = \"Few sample questions and answers are \" + prompt_few_text\n",
    "\n",
    "\n",
    "\n",
    "response = rc.invoke ({\"input\":input_text, \"prompt_text\":prompt_text, \"prompt_examples\": prompt_examples })\n",
    "print ( response['answer'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# older codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retrieval_chain_older (retriever):\n",
    "    # get prompt\n",
    "    # prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "    # print( prompt.messages )\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Answer the questions based on the provided context only.\n",
    "    Please provide the most accurate response based on the question\n",
    "    <context>\n",
    "    {context}\n",
    "    <context>\n",
    "    Questions: {input}\n",
    "    \"\"\")\n",
    "\n",
    "    #llm = Ollama(model = \"llama2\")\n",
    "    llm= ChatOllama(model=\"llama2\")\n",
    "\n",
    "    # creating document chain\n",
    "    document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "    retrieval_chain = create_retrieval_chain (retriever, document_chain)\n",
    "    return retrieval_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retrieval_chain_new (retriever):\n",
    "    # get prompt\n",
    "    # prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "    # print( prompt.messages )\n",
    "    few_shot_examples = [{\"Input\":\"where was Iptacopan discovered?\", \"Output\": \"iscovered at the Novartis Biomedical Research, iptacopan is currently in development for a range of complement-mediated diseases including paroxysmal nocturnal hemoglobinuria (PNH), immunoglobulin A nephropathy (IgAN), C3 glomerulopathy (C3G), immune complex membranoproliferative glomerulonephritis (IC-MPGN) and atypical hemolytic uremic syndrome (aHUS)\"}, \n",
    "                         {\"Input\":\"How does Iptacopan compares with Soliris\", \"Output\": \"Iptacopan was compared to AstraZeneca/Alexion’s Soliris (eculizumab) and Ultomiris (ravulizumab). Both drugs are anti-complement component 5 (C5) monoclonal antibodies, approved for PNH and atypical hemolytic uremic syndrome, generalized myasthenia gravis and neuromyelitis optica spectrum disorder\"}]\n",
    "    few_shot_template  = ChatPromptTemplate.from_messages(\n",
    "     [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\")\n",
    "    ] )\n",
    "\n",
    "    few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "        example_prompt=few_shot_template,\n",
    "        examples=few_shot_examples,\n",
    "    )\n",
    "\n",
    "    #llm = Ollama(model = \"llama2\")\n",
    "    llm= ChatOllama(model=\"llama2\")\n",
    "\n",
    "    # creating document chain\n",
    "    document_chain = create_stuff_documents_chain(llm, few_shot_prompt)\n",
    "    retrieval_chain = create_retrieval_chain (retriever, document_chain)\n",
    "    return retrieval_chain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
